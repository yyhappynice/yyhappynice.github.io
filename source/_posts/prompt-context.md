---
title: 提示工程到上下文工程的转变
date: 2025-11-26 10:05:15
categories:
  - ai笔记
tags:
  - 人工智能
  - 机器学习
---

## 引言

随着 AI Agent 的快速发展，一个新的名词「**上下文工程**」进入大家的视野，很多人会好奇它与「提示词工程」有什么区别，是又在造新的概念吗？我们今天就来聊聊，究竟什么是「上下文工程」，以及它是如何工作的。

本文将围绕三个核心主题展开：

1. **概念定义**：介绍上下文工程的基本概念和核心组成部分。

2. **业界工程实践**：深入分析业界知名产品在上下文工程方面的具体实践。

3. **未来展望**：探讨上下文工程后续可能的演进方向。

今天我们将探讨的问题：

* 为什么需要上下文工程？
* 为什么 Claude Code 效果这么好？
* Manus 在优化 Agent 上做了哪些尝试？
* 为什么 **Spec Driven + Context Engineering** 会代替 **Vibe Coding + Prompt Engineering**？

## 概念定义

### 什么是上下文工程

上下文工程是指构建动态系统，以合适的格式为大语言模型（LLM）提供正确的信息和工具，从而让LLM能够合理地完成任务。

上下文不仅指你发送给 LLM 的单一提示词（prompt），更应该被视为模型在生成响应前所看到的一切信息。上下文工程就是如何将合适的信息填充到有限的上下文里的艺术和科学。

其核心特点包括：

* 动态构建系统
* 提供正确信息和工具
* 合适的格式化
* 让LLM合理完成任务

![Image](https://github.com/user-attachments/assets/beac08aa-5fa5-4d88-b932-5d2fe9ff5c5e)

### 上下文工程的组成部分

一个完整的上下文工程系统包含以下**七个核心组成部分**：

1. **指令/系统提示词**：定义模型整体行为的初始指令，可以（也应该）包含示例、规则等。

2. **用户提示词**：用户提出的即时任务或问题。

3. **当前状态或对话历史（短期记忆）**：用户和模型此前的对话内容，展现当前交流的背景。

4. **长期记忆**：跨多次对话积累的持久性知识库，比如用户喜好、历史项目摘要、记住的特定事实。

5. **检索的信息（RAG）**：外部的、最新的信息，包括从文档、数据库或 API 获取的相关内容，用于回答特定问题。

6. **可用工具**：模型可以调用的所有函数或内置工具定义（如检查库存、发送邮件等）。

7. **结构化输出**：明确定义模型输出的格式，例如 JSON 格式的对象。

### 提示工程 vs 上下文工程

![Image](https://github.com/user-attachments/assets/cbf9854b-97a5-4f4b-8613-b75d852c3143)

Context Engineering 代表着从传统 Prompt Engineering 到新范式的转变。

![Image](https://github.com/user-attachments/assets/3a587a0e-0f0e-4340-bfc0-3d9d9e71a6df)

| 对比维度           | Prompt Engineering | Context Engineering     |
|--------------------|------------------|-------------------------|
| 关注点      | 词句技巧和表达方式          |   提供全面上下文  |
| 作用范围    | 只限于任务描述的表达 | 包含文档、示例、规则、模式和验证 |
| 类比      | 就像贴一张便签              | 就像写一部详细剧本        |

### 为什么需要上下文工程

#### 简单演示对比

让我们通过一个简单的演示来理解上下文工程的价值：

上下文贫乏的情况：

> 用户："Hey, just checking if you’re around for a quick sync tomorrow. 嘿，想问一问明天方不方便，我们快速碰个头？"
> AI："Thank you for your message. Tomorrow works for me. May I ask what time you had in mind? 感谢来信！明天我有空。你想约在几点？"

上下文丰富的"神奇"产品：

> 上下文：你的日历信息（显示你日程已满）、你与此人的过往邮件（用于确定合适的非正式语气）、你的联系人列表（用于识别 ta 为关键的合作伙伴）、send_invite 或 send_email 工具。
> AI："Hey Jim! Tomorrow’s packed on my end, back-to-back all day. Thursday AM free if that works for you? Sent an invite, lmk if it works. 嗨 Jim！明天我这边日程全排满了，从早到晚连轴转。周四上午有空，你看行不？邀请已发，确认下是否合适~"

#### 上下文工程的价值

上下文工程能够带来以下重要价值：

1. **降低 AI 失败率**：大多数 Agent 失败不是模型问题，而是上下文不全。

2. **保证一致性**：AI 能遵循你的项目模式和规范。

3. **支持复杂特性**：有了完整上下文，AI 能处理多步骤实现。

4. **自我修正**：验证循环让 AI 能自动修正错误。

## 业界工程实践概览

在上下文工程领域，有三个产品代表了不同的实践方向：

1. **LangChain**：代表 Agent 框架和工具集合，早期的 Agent 框架，提供了各种Agent开发的基础设施，提出了一套上下文管理的方法论。

2. **Claude Code**：代表 Code Agent 能力上限，编码 Agent 的能力标杆，在长短记忆、分层多 Agent 协作等方面有独到实践。

3. **Manus**：重新展现 Agent 能力，让 Agent 回到大众视野，带动 MCP 发展，在工具使用、缓存设计等方面有独到实践。

### 长上下文的Context-Rot问题

随着上下文长度的增加，模型的注意力机制可能会出现"腐蚀"现象，导致对关键信息的关注度下降。

![Image](https://github.com/user-attachments/assets/8a4610a0-9a90-47a3-8fd0-d56d863000cd)

#### 问题表现

* 产生幻觉后，会被持续带偏。
* 模糊性导致信息冲突，模型的行为会变得不可预测。
* 关键信息被稀释，随着上下文的增长，模型的注意力会被分散。
* 大量重复文本导致的"行动瘫痪"。

#### 影响因素

* 上下文长度超过训练时的常见长度。
* 模型能力的限制。
* 信息密度不均匀分布。
* 自然语言的模糊性。

#### 解决方案

为了解决长上下文带来的问题，业界提出了系统性的上下文工程方法论：

* **Offload**：通过引用减少上下文长度。
* **Retrieve**：RAG 技术动态检索相关信息。
* **Reduce**：压缩裁剪冗余信息。
* **Isolate**：分而治之，通过SubAgent处理子任务。

因此系统性的上下文工程方法论显得尤为重要。

### LangChain的上下文管理方法论

LangChain 提出了**四类上下文管理的基本方法**：

![Image](https://github.com/user-attachments/assets/3a01f04a-a82f-43c5-a0d3-d47763a81e7d)

#### 写入（Offload）上下文

将信息保存在上下文窗口之外，以帮助 Agent 完成任务。不要将工具返回的全部原始信息都直接喂给 LLM。相反，应将其"卸载"到外部存储（如文件系统、数据库或一个专门的代理状态对象中），然后只将一个轻量级的"指针"返回给模型。

核心组件包括：

* File System - 文件系统
* Memories - 长期记忆系统(zep, mem0)
* DataBase - 数据库存储

应用场景：

* 长期记忆构建-claude
* 任务计划保存-manus
* 用户偏好记录
* 知识库管理

#### 选择（Retrieve）上下文

简单来说就是我们所熟悉的 RAG，通过检索和过滤相关信息，来控制进入 Context 的内容的数量和质量。

核心组件：

* 更高级的检索（agentic search）- 从向量检索出发，逐渐往更复杂的搜索体系演化。例如混合召回，结合图谱的 GraphRAG，rerank 等等。
* 返璞归真的文本检索 - 仅仅使用 llms.txt + grep/find 之类的工具，通过 agent 的多轮工具调用来获取相关信息。这也是 Claude Code 的实现方式。

应用场景：

* 代码索引：DeepWiki
* todolist 召回
* 过多工具的召回 langgraph-bigtool（Manus 不推荐，可能导致缓存失效）
* 知识库

#### 压缩（Compress）上下文

通过各种手段来裁剪上下文的内容，只保留完成任务所需的 tokens。

![Image](https://github.com/user-attachments/assets/a7830c67-b01c-417a-a6f3-2fe35a18ca78)

核心组件：

* 摘要生成 - 提取核心信息。
* Rerank - 移除不太相关的信息，RAG 场景中常用。
* 语义总结、压缩 - 保持含义精简表达。如果总结得不好，一样会出现关键信息丢失，甚至引入幻觉等问题。

应用场景：

* 网络搜索
* RAG
* 大量工具使用
* 多轮聊天

#### 隔离（Isolate）上下文

非常类似 Workflow 时代的"分而治之"思想，如果一个任务的 context 压力太过巨大，我们就拆分一下，分配给不同的 sub agents 来完成各个子任务。这样每个 agent 的 context 内容都是独立的，会更加清晰和聚焦。

![Image](https://github.com/user-attachments/assets/8db66629-faa3-45b1-a5ba-f4eae99470bc)

核心组件：

* 环境隔离 - 环境/沙盒隔离，让部分内容在 LLM 环境外运行，如代码执行场景，非常类似"卸载"。
* 多 Agent 分离 - 不同角色独立上下文，容易产生冲突的工作尤其要注意。"只读"类的工作最合适。

应用场景：

* 智能体中涉及代码执行或数据分析。
* 智能体工具调用。
* 复杂的多智能体系统如 Manus。

### Claude Code的工程实践

Claude Code 作为编码 Agent 的标杆，在上下文工程方面有很多独到的实践：

* 三层记忆架构：实现从实时访问到持久化存储的完整覆盖。
* 实时 Steering 机制：流式输出提供持续交互反馈。
* 分层多 Agent 协作：主 Agent 协调 + SubAgent 执行的分层架构。
* 动态上下文注入：自动识别和注入相关文件内容。

#### 三层记忆架构

在长对话中，上下文管理面临 Token 限制导致信息丢失、传统压缩方法破坏上下文连续性、无法支持复杂多轮协作任务等挑战。

Claude Code 的解决方案是构建三层记忆系统：

* 短期记忆（当前对话）
* 中期记忆（智能压缩）
* 长期记忆（CLAUDE.md 项目知识库）

实现从实时访问到持久化存储的完整覆盖。

关键要点：

* 92% 阈值自动触发智能压缩
* 8 段式结构化保存核心信息
* 跨会话恢复项目背景和用户偏好





## 总结

通过对 Claude Code、Manus 和 Kiro 等产品的分析，我们可以看到上下文工程在现代 AI 系统中的关键作用。它不仅解决了传统提示词工程的局限性，还为构建更智能、更可靠的 AI Agent 提供了系统化的方法论。

从 LangChain 的四类上下文管理方法，到 Claude Code 的三层记忆架构和实时 Steering 机制，再到 Manus 的 KV 缓存优化和工具遮蔽技术，以及 Kiro 的规范驱动开发模式，业界正在不断探索和完善上下文工程的最佳实践。

未来，随着环境工程概念的成熟，我们将看到 AI 系统从被动接受上下文走向主动感知和塑造环境，实现更高级别的智能交互。
