---
title: LLM 微调技术
date: 2025-10-12 14:33:49
categories:
  - ai笔记
tags:
  - 人工智能
  - 机器学习
mathjax: true

---

LLM 微调 (Fine-tuning) 是一种**通过特定领域数据对预训练语言模型进行二次训练的技术**。目的是在保持模型通用语言理解能力的基础上，使其适应特定任务或领域。

通过微调技术，基础模型可以显著提升在<u>目标领域（如医疗、法律、金融等）的表现。</u>

![Fine-tuning](https://github.com/user-attachments/assets/b21a5b57-0e14-45b2-afdc-cdcab44fc25c)

### 微调过程
典型微调流程包括以下步骤：

* **选择基础模型**：使用预训练好的通用语言模型（如 Qwen、LLaMA 等）作为起点
* **准备领域数据**：收集与目标领域相关的标注数据集
* **调整超参数(Hyperparameters)**：设置合适的学习率、训练轮次等参数（通常比预训练时更小, 这些都是超参数）
* **领域适应训练**：在保持原有参数的基础上，用领域数据继续训练模型
* **评估验证**：通过领域特定的评估指标检验微调效果
* **迭代上述过程**，来获得更好的结果直到满意

### 微调的优点

* 显著提升特定任务/领域表现
* 数据效率高（相比从头训练）
* 计算资源需求相对较少
* 灵活性高（可针对不同场景定制）

### 微调可能存在的问题

* **过拟合风险**：过度适配训练数据可能导致泛化能力下降
* **领域依赖**：在非目标领域表现可能下降
* **需要领域专业知识**：数据准备和评估指标设计需要领域知识
* **计算资源需求**：虽然比预训练少，但仍需要可观资源

### 大模型微调最佳实践指南

### 什么时候应该微调, 什么时候不应该微调?
